# Hongong Machin Learning and Deep Learning chapter 2
## 2-1. 훈련 세트 테스트 세트 
- 지도 학습과 비지도 학습의 차이를 배워보고, 모델을 훈련시키는 훈련 세트와 모델을 평가하는 테스트 세트로 데이터를 나눠서 학습하기
#### * 책 페이지: "혼자공부하는 머신러닝 + 딥러닝" P66 ~ P86
#### * 참고 코드: "2-1_training_set_and_test_set.ipynb"
### 과정 
- 지도학습과 비지도 학습의 정의
- 훈련 세트와 테스트 세트 정의
- 샘플링 편향 정의
- 넘파이 패키지 활용
- 훈련 세트와 테스트 세트로 두 번째 머신러닝 프로그램 구축
### 정리 및 결론
- 과정 정리 
  - chapter 1의 모델 평가 방식이 이상다는 의견을 제기
  - 모델을 훈련할 때 사용하는 데이터로 모델의 성능을 평가하는 것은 정답을 미리 알려주고 시험을 보는 것과 같음, 공정하게 점수를 매기지 않기 위해서는 훈련에 참여하지 않은 샘플을 이용해야 한다고 판단.
  - 훈련 데이터를 훈련 세트와 테스트 세트로 나눔 (훈련 세트는 모델 훈련을, 테스트 세트는 모델을 평가를)
  - 하지만 테스트 세트를 무작정 나누어선 안됨, 도미와 빙어를 분류하는 것이 목적이므로 훈련 세트나 테스트 세트에 어느 한 생선만 들어가면 올바른 학습이 이루어지기 힘듬.
  - 골고루 데이터를 섞기 위해 넘파이 라이브러리에 shuffle 함수를 사용. 배열의 인덱스를 섞어 다시 모델을 훈련시킴
- 결론
  - 테스트 세트에서 정확도 100% 모델 구축 

## 2-2. 데이터 전처리 
- 올바른 결과 도출을 위해 데이터를 사용하기 전 데이터 전처리 과정을 거치는데, 이 과정을 거친 데이터로 훈련했을 때의 차이를 알고 표준점수로 특성의 스케일을 변환하는 방법을 학습해보기
#### * 책 페이지: "혼자공부하는 머신러닝 + 딥러닝" P87 ~ P111
#### * 참고 코드: "2-2_preprocessing_dataset.ipynb"
### 과정 
- 넘파이로 데이터 준비
- 사이킷 런으로 훈련 세트와 테스트 세트 나누기
- 새로운 샘플 데이터로 훈련된 모델링에 적용하기
- 스케일링 작업
- 전처리한 데이터로 다시 모델 훈련, 결과 도출 
### 정리 및 결론
- 과정 정리 
  - 첫 머신러닝 알고리즘을 바탕으로 다른 도미 샘플 데이터를 대입해보니 빙어라고 예측
  - numpy이를 이용하여 train, test 데이터를 만들고 sklearn 패키지를 이용하여 train, test를 나눔.
  - 다시 모델을 평가하고 예측을 해보니 또 똑같이 빙어라고 예측 함, 산점도 그래프를 살펴보면 또 산점도가 도미에 가까움을 나타내는 희한한 상황이 발견됨.
  - 하지만 이는 각 특성마다 스케일이 다른 것임을 발견하고, 표준점수로 변환하여 스케일을 조정함.
- 결론
  - 받은 도미 샘플 데이터를 다시 대입하여 모델을 평가하고 예측한 결과 정확도 100%, 도미를 제대로 예측함.
- 주의할 점
  - 대부분 머신러닝 알고리즘은 특성의 스케일이 다르면 잘 작동하지 않음, 이를 위해 특성을 표준점수로 변환함 (다른 방법도 있지만, 대부분의 경우 표준점수 변환의 방법을 사용함.)
  - 데이터 전처리를 할 때 주의할 점은 훈련 세트를 변환 방식 그대로 테스트 세트도 똑같이 변환해줘야 한다는 점이다. (안그러면 엉뚱하게 변환해서 모델이 쓸모없어지는 결과가 나온다.)   
