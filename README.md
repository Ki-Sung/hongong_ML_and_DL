# Hongong Machin Learning and Deep Learning chapter 5
## 5-1. 결정 트리 
#### * 책 페이지: "혼자공부하는 머신러닝 + 딥러닝" P220 ~ P241
#### * 참고 코드: "5-1_decision_tree.ipynb"
### 과정 
- 로지스틱 회귀로 와인 분류하기
  - 설명하기 쉬운 모델과 어려운 모델 
- 결정트리 
  - 불순도
  - 가지치기 
### 정리 및 결론
- 과정 정리 
  - 가을 신상품으로 준비한 캔 와인은 실수로 와인의 종류(레드 와인 / 화이트 와인)가 캔에 인쇄되지 않았다.
  - 알코올 도수, 당도, pH 데이터를 기준으로 화이트 와인을 골라내는 이진 분류 로지스틱 회귀 모델을 훈련 했지만, 다른 사람이 보고서를 이해할 수 없었다.
  - 그래서 결정 트리를 사용해 레드 와인과 화이트 와인을 분류하는 문제를 풀었다.
  - 특성을 더 추가하지 않고도 결정 트리의 성능이 로지스틱 회귀 모델보다 더 좋음을 알 수 있었다. 게다가 결정 트리는 깊이가 너무 깊지 않다면 비교적 설명하기 쉬웠다.
  - 그리고 결정 트리가 어떻게 데이터를 분할하는지 이해하기 위해 불순도 개념과 정보 이득에 대해 알아보았다.
- 결과
  - 머신러닝 모델을 종종 블랙박스와 같다고도 말한다. 실제로 모델의 계수나 절편이 왜 그렇게 학습되었는지 설명하기가 어렵다.
  - 하지만 결정 트리는 비교적 비전문가에게도 설명하기 쉬운 모델을 만들어 낸다.
  - 결정 트리는 여기서 끝이 아니다. 결정 트리는 많은 앙상블 학습 알고리즘의 기반이 된다. (앙상블 학습은 신경망과 함께 가장 높은 성능을 내기 때문에 인기가 높은 알고리즘이다.)  
